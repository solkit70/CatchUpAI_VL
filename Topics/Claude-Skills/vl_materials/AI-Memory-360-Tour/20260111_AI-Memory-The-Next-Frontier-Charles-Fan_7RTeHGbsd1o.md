# AI Memory, The Next Frontier - Charles Fan

**원본 영상**: [https://www.youtube.com/watch?v=7RTeHGbsd1o](https://www.youtube.com/watch?v=7RTeHGbsd1o)
**작성일**: 2026-01-11
**Video ID**: 7RTeHGbsd1o

---

## 요약

MBER의 CEO Charles Fan이 AI 메모리가 차세대 AI 혁명의 핵심 인프라가 될 것이라는 비전을 제시합니다. 그는 AI 메모리를 단순한 저장소가 아닌 살아있는 지능형 시스템으로 정의하며, 기업과 개인의 가장 가치있는 자산이 될 것이라고 주장합니다. MBER는 이를 구현하기 위해 오픈소스 프로젝트 'Project Man'을 공개했습니다.

---

## 핵심 포인트

- 대규모 언어모델이 새로운 컴퓨터가 되면서 AI가 생성한 데이터를 저장할 새로운 플랫폼이 필요함
- AI 메모리는 전통적인 데이터베이스와 달리 살아있고, 능동적이며, 지능적인 시스템임
- AI 메모리는 기업의 본질을 형성하며 모델과 에이전트를 연결하는 공통 데이터 패브릭 역할을 함
- 메모리는 사용자가 소유하고 제어해야 하며, 특정 모델 제공자에게 종속되어서는 안 됨
- MBER는 오픈소스 프로젝트 'Project Man'을 통해 에피소드 메모리, 프로필/의미론적 메모리, 절차적 메모리를 구현 중

---

## 주요 내용

### 섹션 1: AI 메모리의 필요성
- 대규모 언어모델이 새로운 컴퓨터 패러다임이 됨
- 모델과 에이전트가 생성하는 데이터를 저장할 새로운 시스템 필요
- 모델 자체는 설계상 데이터를 기억할 수 없으며(프라이버시 보호 목적), 별도의 저장 시스템이 필수적
- 적절한 시점에 적절한 컨텍스트를 제공하여 AI 응답의 정확성과 개인화를 향상

### 섹션 2: AI 메모리의 특성
- 전통적인 데이터베이스나 스토리지와는 근본적으로 다름
- 인간의 기억처럼 살아있고 능동적이며 지능적인 시스템
- 단순한 저장(put)과 검색(get)을 넘어서 지속적으로 진화함
- 시간이 지남에 따라 쇠퇴하고, 통합되고, 관계를 통해 재구성됨
- 자율적이고 능동적인 에이전트로서 기능

### 섹션 3: AI 메모리의 가치와 역할
- AI가 생성한 데이터가 향후 모든 데이터의 대다수를 차지할 것
- 기업의 조직적 지식을 보존하는 핵심 자산이 됨
- 기업 A를 기업 A답게 만드는 본질적 요소
- 모델과 에이전트는 변화하지만 메모리는 영속적임
- 수백, 수천 개의 에이전트를 연결하는 공통 데이터 패브릭 역할

### 섹션 4: 산업 동향
- OpenAI(GPT-5, GPT-6), Anthropic(Claude), Google(Gemini) 등 주요 기업들이 메모리 기능 강조
- 대기업들의 메모리 시스템은 자사 모델에만 밀접하게 결합되어 있음
- 사용자 경험 향상과 락인(lock-in) 효과를 위한 전략
- 메모리가 구축되면 모델과의 연결이 훨씬 강해짐
- 독립적이고 통합된 메모리 시스템의 필요성 대두

### 섹션 5: 오픈소스 대안의 필요성
- 100개의 서비스를 사용할 때 100개의 메모리가 아닌 하나의 통합 메모리 필요
- 모든 AI 서비스의 데이터를 포착하여 상호 활용 가능하게 함
- 메모리의 소유권과 통제권이 특정 서비스가 아닌 사용자에게 있어야 함
- 오픈소스 또는 독립적인 제품/서비스로 구현 가능
- 메모리 중심 인프라는 거대한 시장을 창출할 것으로 예측됨

### 섹션 6: Project Man 소개
- MBER가 몇 주 전 GitHub에 오픈소스로 공개한 AI 메모리 프로젝트
- 다양한 모델, 에이전트, 어시스턴트, 사용자가 접근 가능
- MCP 서버, HTTP/HTTPS RESTful API, Python SDK 제공
- 클라우드(AWS), 데이터센터, 개인 노트북, 모바일에 배포 가능
- 언어에 구애받지 않으며 모든 텍스트 데이터 지원 (멀티모달은 향후 계획)

### 섹션 7: 메모리 구성 요소 - 에피소드 메모리
- 이벤트와 에피소드를 기억하고 메모리 엔티티로 구성
- 엔티티 간의 관계를 생성하여 미래 쿼리에 적절한 컨텍스트 제공
- **단기/작업 메모리**: DRAM에 저장, 최근 에피소드의 즉각적 검색
- **장기 메모리**: 영구 저장소에 보관, 모든 과거 에피소드 포함
- 살아있는 머신으로서 시간이 지남에 따라 동적으로 구성, 재구성, 통합

### 섹션 8: 메모리 구성 요소 - 프로필/의미론적 메모리
- 현재 버전: 프로필 메모리, 다음 주 버전 0.2에서 의미론적 메모리로 일반화 예정
- 모든 에피소드에서 주요 속성을 추출 (요약 또는 투영)
- 내부 직원 및 외부 고객의 초상(portrait) 구축
- AI 서비스의 개인화 활성화
- 에이전트가 내부 및 외부 사용자에게 더 맞춤화된 서비스 제공 가능

### 섹션 9: 메모리 구성 요소 - 절차적 메모리
- 절차 또는 워크플로우의 기억
- 특정 작업을 수행하는 방법을 포착하는 일련의 동작
- 초기 형태: Closed Skills (약 10개월 전 발표)
- 더 발전된 형태의 절차 관리 필요
- 기업 내 생산성 향상에 직접 기여
- 아직 개발 중이며 오픈소스에 미포함

### 섹션 10: 지원 에이전트
- **데이터 주입 에이전트**: 
  - 모든 데이터 소스에 연결하여 메모리로 수집
  - 채팅 기록, 사용자-에이전트-모델 상호작용뿐만 아니라 사용자 간 상호작용도 포함
  - Slack, 이메일, 회의록 커넥터 구축
  
- **컨텍스트 검색 에이전트**:
  - 쿼리를 다양한 메모리 부분으로 하위 쿼리로 변환
  - RAG 시스템 등 다른 컨텍스트 소스에서도 검색
  - 전체 컨텍스트 강화를 위해 결과를 조합
  - MCP 서버를 통한 모델의 직접 쿼리 지원
  - 전체 컨텍스트 엔지니어링 시스템의 핵심 모듈

### 섹션 11: 현재 상태 및 향후 계획
- 여정의 초기 단계 (버전 0.1)
- 다음 주 버전 0.2에서 큰 개선 예정
- 초기 형태의 두 에이전트 포함, 활발히 개발 중
- 텍스트 데이터만 지원, 멀티모달(음성, 이미지, 비디오)은 향후 추가 예정
- 하부에 데이터베이스 사용하여 메모리 엔티티와 프로필 저장
- 협업과 정보 공유, 표준 및 벤치마크 생성을 통해 분야 발전 추구

## 결론
Charles Fan은 AI 메모리를 AI 중심 세계의 데이터 기반으로 보며, 이 분야의 초기 탐험가들이 협력하여 더 빠른 발전을 이루어야 한다고 강조합니다. MBER의 Project Man은 이러한 비전을 실현하기 위한 오픈소스 노력이며, 커뮤니티의 참여와 협업을 통해 지속적으로 발전시켜 나갈 계획입니다.

---

## 타임라인

- **00:00**: All right. Uh good morning. Uh my name is Charles and uh I'm a co-founder CEO of MBER. It's great to uh be here with uh really my uh colleagues and my comrades in this uh venture uh into AI memory. Um I want to share uh my uh perspective maybe one perspective on what AI memory is and why I think it is important for the uh authentic AI revolution. Okay. So um you know first of all is something that everyone knows uh that large language model is becoming the new computer. uh before we have a problem uh we uh give it to the computer uh our laptop our PC server or a supercomput and it will compute and give us the results and that's the world we've been used to for the last 60 years or so and uh in the last few years uh we are adapting to another mode which is when we have a problem instead of having computer instead of writing programs and and letting computer answer we ask a model and model would give us the results. So from that perspective uh model is a new computer. It is there to answer questions, to solve problems for us. And to do that, we have agents and assistants uh that are really digital colleagues for us to help us uh using the models to give us the right answers. And while all these new computation are happening, uh there are data being generated just like the old computer. when the whole computer computes their data being generated and then it needs to be saved somewhere and those data can be further used for further computation later on and with this AI the computer they're also data being generated uh these are the data generated by model agents or by the users um now these data needs to be stored somewhere too uh if you want to remember them and model itself cannot remember by design. In fact, it's a problem if the model can't remember during the inference uh then um you lose all the privacy uh of your data when...
- **05:00**: is something that is uh autonomous that's something that is uh is proactive and over time this memory machine in a way uh that can proactively learns and adapts and really retains the institutional knowledge that whether it is for an enterprise whether it is for other organizations or whether it's for individuals that forms the essence of what that enterprise knows and I think over time AI generated data will become the majority of all data And this is different type of data and they will be stored in AI memory and therefore make AI memory the most valuable asset to any institutions or enterprises or individuals. You know our memory is what make Charles Charles and I believe the AI memory for enterprise A is what's going to make the enterprise A the Enterprise A. So, so this is over time going to be the most valuable uh essence of an organization. Models and agents come and go. Um and uh you nowadays when we talk to enterprise customers there are hundreds or thousands of agents being driven everywhere. Every group within enterprises try to reposition themselves as a agent team and there are hundreds of agent team in a large enterprise and they are all developing agents of themselves and these agents will evolve. uh there's really a sprawl of all these agents that's emerging and AI memory will also serve as a common data fabric that all these agents all these models behind these agents can share so that you can you know putting a common fabric that can connect to this sprawl of agents that are happening today and continue happening tomorrow. Okay, so that's you know a particular angle into AI memory. Um there are certainly other angles into it. It it can make uh the models uh perform better. It can make the agents easier to develop. It has many other benefits but this is one perspective that we believe AI memory will form the data...
- **10:00**: capture data from all the AI service I use so they can benefit from each other and and I want my memory to belong to me not belong to one of those services and uh and I think that's something we could build um you know whether it's an open source or as a product or service that's really giving the owner of the memory the control to the memory they have rather than relinquish that control to the particular models And um and then there are you know other uh news from various sources uh that and people are predicting uh a huge huge market here um that is being uh created and uh it is because of this um in memory centric infrastructure. uh we were at lower level trying to build an infrastructure uh leveraging some emerging new hardware um and uh over the last couple years we have shifted uh pivoted our attention to this field of AI memory and uh we've been making on a uh project uh open source project called project man and uh this is our effort uh in uh attacking the AI memory problem and uh and it is uh available on GitHub. Uh we open sourced it a few weeks ago and uh and here is a simplistic uh block background uh describing what's included in that project. Um and this blue box is our memory system and it is accessible by various models, agents, assistance or directly by users through a various uh APIs uh or interfaces. Um it has a MCP server that can be visited directly by models or by agents or by other uh software. uh it has a HTTP and HTTPS endpoint. Uh that's the restful API that can also be called by any other piece of software. It's also uh an Python SDK that can be integrated with your agents and your applications directly. And within the memory uh system that uh we have uh three piece of memory two of these are available today. The other piece we are still working out and we haven't open source yet. Uh the first piece is episodic memory and this is...
- **15:00**: and external users. Uh and the third component is procedural memory and this is a memory of the procedures or of the workflows. Uh and that's is a sequence of actions uh that uh captures how certain task to be done. you know early primitive form of procedures is like closed skills if you're familiar with that that was announced maybe 10 months ago uh and uh and that's kind of the primitive form and now they're more advanced form and there needs to be better management of all these uh procedures and I think this can directly contribute to the productivity boost within the enterprise and procedural memory is something we are still working on and that's not available in the open source project yet but The other two pieces are there. We are only at the beginning of journey. It's like 0.1 and we are continue to improve it. You'll see a big boost next week with our 0.2. Um we also included a couple agents within our memory and those are the orange boxes on the top. The data injection agent is responsible for connecting to all the data sources and to ingest them into various memories that we have. uh so that uh the uh memory can be enriched not only from all the chat history or the user agent or agent user model interactions uh but also potentially from user user interactions. So for example, we have uh built connectors to slack uh to emails to meeting transcripts so that you can capture all those episodes into the memory system as well. The second agent is contact retrieval agent. And the contact retrieval agent is responsible for when you see a query that you can translate that query into subqueries into different pieces of memory or potentially into other uh context sources like rack systems where many enterprise have them today. And it is then responsible for assemble them together to form the overall uh context enrichment uh to queries. And so this...
- **20:00**: maybe there are better words for that people who share the same vision here and who are who are building it and uh and and these are uh some of the results we we gathered from the published materials uh of the benchmark uh using a benchmark for local and and that seems to be a popular benchmark with all the people who are working on memory. Um and uh uh actually I forgot to change the typo because we our latest 0.1 is achieving the statewide uh in terms of local performance. Uh as you see some of the other players they will probably publish new data to elevate continue to elevate their performance as well. But from what we gathered from the published material, we saw that open AI uh is about 52%. So how this benchmark works is it feeds 10 long conversations u into the memory system and then it generate about 1900 questions. It would ask the model which is integrated with that particular memory system. If it doesn't have a memory, it it only will get very small percentage of those questions correctly. But with a memory system now, I can't answer all of them correctly. So the openi answer about 52% correctly and man with a memory system will event the numbers they have is what I got is 66 to 75%. they probably have new or better numbers uh as we make progress. Um I think uh uh when we launched the project in September we published numbers at 84.87% and in the last couple months uh with our new improvement uh our latest performance 93.25%. And from the numbers that we have seen I think this is a state of art uh in the episodic memory performance. uh we do see a new announcement from uh uh last weekend uh from uh Evermind and who I think will tank will be presenting today. They are publishing 92.3% which is a very good result uh as well....
- **25:00**: with a with a particular customer and how I go about and doing it is I first work with KBD um and KPD is powered by mechain behind and uh so it will be able to uh retrieve the relevant information from my memory system about uh Apex tack from all the meeting minutes and emails and Slack conversation that we've had about this uh uh customer as well as from past AI uh chat box or chat history about them and it'll be able to summarize them deliver me information about the customer uh it will remember things about the product I'm going to present and it's also going to remember about me so it's gonna the profile memory going to deliver uh what is Charles like? uh what uh do I like you know what type of slides I like to make and what type of flow I like to follow and all those information will be automatically served as context into models and model will be able to generate in this case open AI model will be generating a presentation outline and but I don't like for the actual poweroint it's actually not yeah it's not good at that so then I will will you know bring up my clo uh desktop and uh now clo all those conversations with JBT is automatically real time captured by membership memory system and and clo will be able to use that interaction give me some additional advices and actually go ahead and generate a particle. So this shows a typical scenario where a knowledge worker like myself can use multiple agents, multiple models or connected through a memory fabric to getting a task done very easily. >> Yes. >> So when you use the chat GBT right based on the me machine do your interactions feed back to the memory? >> Yes. >> Yeah. when we are actually using the CHP those interactions are automatically in the background uh being remembered by yes and and and now let me show the...
- **30:00**: create the the slides here. So so you'll see it's creating actually nine nine slides here uh as we have taken one suggestion from it and voila you have the uh the slides is created. uh and this is a seamless process where you use multiple agents powered by different models but connected to a common converg management system that can deliver uh the output you need and uh and this is a simple example uh pretty common scenario I think all of us do that there are many other common scenarios where a common converge AI memory fabric can enable this multi- aent collaboration to happen seamlessly Okay. All right. So that's the uh uh example I have and then as you see there there's many use cases for something like this. Now whether you're creating assistance to various roles, whether it's executives, creative content creators, or whether you're serving external clients uh or financial advice or customer support, a memory system is quintessential uh in delivering uh the state-of-the-art agents uh for these purposes. Uh so try it out. Uh here is a barcode for the project and this will connect you to GitHub to our playground to uh uh other resources, documentations and so on about the project that will dive into much more details and my presentation and we also have a team here uh that you can scan this to schedule a meeting that can happen today. We have a room oneonone with our team to learn more about the memory. And for those folks on the zoom, you know, you can also use this to to schedule meetings uh with us uh to dive into more details. So, thank you very much....

---

## 전체 자막 (타임스탬프 포함)

**[00:03]** All right. Uh good morning. Uh my name

**[00:07]** is Charles and uh I'm a co-founder CEO

**[00:10]** of MBER. It's great to uh be here with

**[00:14]** uh really my uh colleagues and my

**[00:18]** comrades in this uh venture uh into AI

**[00:23]** memory. Um I want to share uh my uh

**[00:27]** perspective maybe one perspective on

**[00:30]** what AI memory is and why I think it is

**[00:33]** important for the uh authentic AI

**[00:38]** revolution.

**[00:40]** Okay. So um you know first of all is

**[00:44]** something that everyone knows uh that

**[00:48]** large language model is becoming the new

**[00:51]** computer. uh before we have a problem uh

**[00:55]** we uh give it to the computer uh our

**[00:58]** laptop our PC server or a supercomput

**[01:03]** and it will compute and give us the

**[01:06]** results and that's the world we've been

**[01:09]** used to for the last 60 years or so and

**[01:13]** uh in the last few years uh we are

**[01:17]** adapting to another mode which is when

**[01:19]** we have a problem instead of having

**[01:22]** computer instead of writing programs and

**[01:24]** and letting computer answer we ask a

**[01:27]** model and model would give us the

**[01:29]** results. So from that perspective uh

**[01:32]** model is a new computer. It is there to

**[01:35]** answer questions, to solve problems for

**[01:38]** us. And to do that, we have agents and

**[01:40]** assistants

**[01:42]** uh that are really digital colleagues

**[01:45]** for us to help us uh using the models to

**[01:50]** give us the right answers. And while all

**[01:52]** these new computation are happening,

**[01:57]** uh there are data being generated just

**[01:59]** like the old computer. when the whole

**[02:00]** computer computes their data being

**[02:03]** generated and then it needs to be saved

**[02:06]** somewhere and those data can be further

**[02:09]** used for further computation later on

**[02:13]** and with this AI the computer they're

**[02:15]** also data being generated uh these are

**[02:18]** the data generated by model agents or by

**[02:21]** the users um now these data needs to be

**[02:25]** stored somewhere too uh if you want to

**[02:28]** remember them and model itself cannot

**[02:32]** remember by design. In fact, it's a

**[02:35]** problem if the model can't remember

**[02:37]** during the inference uh then um you lose

**[02:41]** all the privacy uh of your data when

**[02:44]** you're using model to do so. So there

**[02:47]** need to be a separate system that sort

**[02:50]** of a new database or a new storage for

**[02:53]** the data that the app generates. And in

**[02:55]** my point of view uh that system is AI

**[03:00]** memory. So AI memory is the new data

**[03:04]** platform

**[03:05]** uh for

**[03:07]** uh the AI generated data and uh um and

**[03:12]** and this is now um responsible for

**[03:16]** remembering them and recalling them at

**[03:18]** the right time so that the right context

**[03:22]** can be delivered to the model at the

**[03:24]** right time. and context is very

**[03:27]** important for the accuracy and

**[03:30]** personalization of the AI responses uh

**[03:34]** from models to the question to those

**[03:36]** questions and uh so the memory will need

**[03:39]** to do that. Now you might ask why

**[03:42]** couldn't we just use a classic storage

**[03:44]** or classic database to do so. Um and in

**[03:48]** our point of view and I think probably

**[03:51]** all of your point of view that this

**[03:54]** requirement for this AI memory is quite

**[03:57]** different from the classical databases

**[04:00]** or data stores. Uh just like human

**[04:03]** memory

**[04:05]** the memory is a living thing. It's

**[04:07]** something that's active. It's something

**[04:09]** that's intelligent. Uh it is not just

**[04:13]** something you store in the tree. Those

**[04:14]** are not the only not only for them get

**[04:17]** those are not the only few actions you

**[04:19]** have with your memory. Uh but rather it

**[04:22]** is something that's constantly evolving.

**[04:25]** It has a life of its own. It decays uh

**[04:29]** it consolidates

**[04:31]** uh and it reorganizes itself uh through

**[04:35]** other relations and connections. So it

**[04:39]** is a living thing by itself. it is

**[04:42]** active uh and and that's something that

**[04:46]** the storage of database are not and

**[04:49]** those are just put and get are the only

**[04:52]** thing you do like you you add memory or

**[04:54]** search and but memory itself in the AI

**[04:58]** world is actually an agent in a cell it

**[05:01]** is something that is uh autonomous

**[05:04]** that's something that is uh is proactive

**[05:07]** and over time this memory machine in a

**[05:12]** way uh that can proactively learns and

**[05:16]** adapts and really retains the

**[05:20]** institutional knowledge that whether it

**[05:22]** is for an enterprise whether it is for

**[05:25]** other organizations or whether it's for

**[05:27]** individuals that forms the essence of

**[05:31]** what that enterprise knows and I think

**[05:34]** over time AI generated data will become

**[05:37]** the majority of all data And this is

**[05:41]** different type of data and they will be

**[05:42]** stored in AI memory and therefore make

**[05:45]** AI memory the most valuable asset to any

**[05:49]** institutions or enterprises or

**[05:52]** individuals. You know our memory is what

**[05:55]** make Charles Charles and I believe the

**[05:59]** AI memory for enterprise A is what's

**[06:03]** going to make the enterprise A the

**[06:06]** Enterprise A. So, so this is over time

**[06:08]** going to be the most valuable uh essence

**[06:11]** of an organization.

**[06:13]** Models and agents

**[06:16]** come and go. Um and uh you nowadays when

**[06:20]** we talk to enterprise customers there

**[06:22]** are hundreds or thousands of agents

**[06:25]** being driven everywhere. Every group

**[06:28]** within enterprises try to reposition

**[06:30]** themselves as a agent team and there are

**[06:34]** hundreds of agent team in a large

**[06:35]** enterprise and they are all developing

**[06:38]** agents of themselves and these agents

**[06:40]** will evolve. uh there's really a sprawl

**[06:43]** of all these agents that's emerging and

**[06:48]** AI memory will also serve as a common

**[06:51]** data fabric that all these agents all

**[06:54]** these models behind these agents can

**[06:57]** share so that you can you know putting a

**[07:01]** common fabric that can connect to this

**[07:04]** sprawl of agents that are happening

**[07:07]** today and continue happening tomorrow.

**[07:10]** Okay, so that's you know a particular

**[07:12]** angle into AI memory. Um there are

**[07:16]** certainly other angles into it. It it

**[07:19]** can make uh the models uh perform

**[07:22]** better. It can make the agents easier to

**[07:25]** develop. It has many other benefits but

**[07:28]** this is one perspective that we believe

**[07:30]** AI memory will form the data

**[07:33]** underpinning of the AI centric world

**[07:37]** that are coming

**[07:39]** and and that makes this event

**[07:41]** significant. I think we are the early

**[07:43]** explorers in this world and uh and

**[07:47]** that's also the reason we would like to

**[07:48]** invite all the folks that we can find

**[07:51]** who are also working in this field uh

**[07:53]** because I think this is going to be a

**[07:55]** huge field and it's going to take the

**[07:56]** effort of all of us to make this happen

**[08:00]** sooner rather than later and we can

**[08:02]** collaborate together in this uh not only

**[08:06]** in information sharing but potentially

**[08:09]** in in the standards creation or

**[08:11]** benchmark uh creation so that we can

**[08:14]** together advancing this uh field

**[08:16]** forward.

**[08:18]** Okay. Now the the industry is also you

**[08:22]** know their announcement happening

**[08:23]** everywhere uh from the big companies to

**[08:27]** many of the startups like uh us um the

**[08:32]** open AI you know with GPT5 and GPT6 that

**[08:37]** they are forecasting are putting a lot

**[08:39]** of emphasis on the memory they are

**[08:41]** creating. Uh cloud is uh catching up and

**[08:45]** uh announcing various um memory

**[08:49]** features. Google has a big announcement

**[08:51]** this week and Gemini is having various

**[08:54]** memory features uh introducing as well.

**[08:58]** Now these are all separate system from

**[09:01]** the model from the flagship model they

**[09:03]** have uh but they are integrate part of

**[09:06]** their service and it's tightly coupled

**[09:09]** uh to their model and uh you know I

**[09:12]** think probably not for technical reason

**[09:14]** but for other reasons their memory

**[09:17]** systems would only support their own

**[09:20]** models. This will make the user

**[09:22]** experience better with their models and

**[09:24]** this will also make the user more

**[09:26]** sticky. uh to their models. Uh you know

**[09:30]** some of you and and myself probably have

**[09:32]** the experience once you have the memory

**[09:34]** built the experience the connection you

**[09:37]** have with models will be much closer

**[09:39]** than without the memory and but that I

**[09:42]** think does leave room for the other

**[09:44]** players because I think this memory

**[09:47]** needs to be converged. I don't want to

**[09:50]** have a 100 different piece of memories

**[09:52]** if I'm using a 100 different AI

**[09:54]** services. I I just want to have one. I

**[09:56]** want wanted it to know me. I wanted to

**[10:00]** capture data from all the AI service I

**[10:03]** use so they can benefit from each other

**[10:05]** and and I want my memory to belong to me

**[10:08]** not belong to one of those services and

**[10:11]** uh and I think that's something we could

**[10:13]** build um you know whether it's an open

**[10:15]** source or as a product or service that's

**[10:19]** really giving the owner of the memory

**[10:21]** the control to the memory they have

**[10:24]** rather than relinquish that control to

**[10:26]** the particular models And um and then

**[10:30]** there are you know other uh news from

**[10:32]** various sources uh that and people are

**[10:36]** predicting uh a huge huge market here um

**[10:40]** that is being uh created and uh it is

**[10:44]** because of this um in memory

**[10:52]** centric infrastructure. uh we were at

**[10:55]** lower level trying to build an

**[10:56]** infrastructure

**[10:58]** uh leveraging some emerging new hardware

**[11:01]** um and uh over the last couple years we

**[11:05]** have shifted uh pivoted our attention to

**[11:09]** this field of AI memory and uh we've

**[11:12]** been making on a uh project uh open

**[11:16]** source project called project man and uh

**[11:20]** this is our effort uh in uh attacking

**[11:24]** the AI memory problem and uh and it is

**[11:29]** uh available on GitHub. Uh we open

**[11:33]** sourced it a few weeks ago and uh and

**[11:36]** here is a simplistic uh block background

**[11:41]** uh describing what's included in that

**[11:45]** project. Um and this blue box is our

**[11:49]** memory system and it is accessible by

**[11:52]** various models, agents, assistance or

**[11:56]** directly by users through a various uh

**[11:58]** APIs uh or interfaces. Um it has a MCP

**[12:03]** server that can be visited directly by

**[12:06]** models or by agents or by other uh

**[12:10]** software. uh it has a HTTP and HTTPS

**[12:15]** endpoint. Uh that's the restful API that

**[12:18]** can also be called by any other piece of

**[12:21]** software. It's also uh an Python SDK

**[12:26]** that can be integrated with your agents

**[12:29]** and your applications directly. And

**[12:32]** within the memory uh system that uh we

**[12:38]** have uh three piece of memory two of

**[12:42]** these are available today. The other

**[12:44]** piece we are still working out and we

**[12:46]** haven't open source yet. Uh the first

**[12:48]** piece is episodic memory and this is

**[12:51]** where you remember the events the

**[12:53]** episodes and how do you

**[12:56]** uh uh organize them into memory entities

**[12:59]** and creating the right relations between

**[13:01]** the entities so that uh the right

**[13:04]** episodes or right memory entities can be

**[13:08]** called to deliver the context for all

**[13:11]** future queries. And within episodic we

**[13:14]** have two modules. One is the shortterm

**[13:17]** working memory and this is all stored

**[13:20]** into DRAM and uh this is meant to

**[13:24]** remember the most recent episodes for

**[13:27]** immediate retrieval uh for the more

**[13:29]** recent events. And then we have a

**[13:31]** long-term memory that is uh uh

**[13:33]** persistent uh and that captures all the

**[13:36]** past episodes and we would uh uh this so

**[13:41]** this is a living machine. able to

**[13:42]** dynamically

**[13:44]** organize them and reorganize them and

**[13:47]** consolidate them over time and uh so

**[13:50]** that they are uh easier they they are

**[13:55]** easy to retrieval or to retrieve when we

**[13:58]** need to find the most relevant entities

**[14:01]** to any queries. And then we have the

**[14:04]** second piece is the profile memory and

**[14:07]** uh we actually are shipping a version.2

**[14:10]** next week and uh and it's going to

**[14:13]** generalize profile memory into semantic

**[14:16]** memory. U so profile memory is a special

**[14:18]** kind of semantic memory where it extract

**[14:22]** uh good attributes from all the

**[14:25]** episodes. So it's kind of a

**[14:26]** summarization or uh a projection from

**[14:31]** this episodes to particular dimensions

**[14:33]** and particular attributes and in

**[14:35]** particular profile memory is to enable

**[14:39]** the personalization of AI services. You

**[14:42]** can use profile profile memory to build

**[14:45]** uh portraits of any of the users whether

**[14:48]** it is internal employees or whether it's

**[14:51]** external clients. So that allow you to

**[14:55]** be more personalized uh in the service

**[14:58]** that agents can deliver uh to internal

**[15:02]** and external users. Uh and the third

**[15:05]** component is procedural memory and this

**[15:08]** is a memory of the procedures or of the

**[15:11]** workflows. Uh and that's is a sequence

**[15:14]** of actions uh that uh captures how

**[15:18]** certain task to be done. you know early

**[15:21]** primitive form of procedures is like

**[15:24]** closed skills if you're familiar with

**[15:26]** that that was announced maybe 10 months

**[15:27]** ago uh and uh and that's kind of the

**[15:31]** primitive form and now they're more

**[15:32]** advanced form and there needs to be

**[15:35]** better management of all these uh

**[15:37]** procedures and I think this can directly

**[15:39]** contribute to the productivity boost

**[15:42]** within the enterprise and procedural

**[15:44]** memory is something we are still working

**[15:46]** on and that's not available in the open

**[15:48]** source project yet but The other two

**[15:50]** pieces are there. We are only at the

**[15:53]** beginning of journey. It's like 0.1 and

**[15:55]** we are continue to improve it. You'll

**[15:56]** see a big boost next week with our 0.2.

**[16:00]** Um we also included a couple agents

**[16:03]** within our memory and those are the

**[16:05]** orange boxes on the top. The data

**[16:08]** injection agent is responsible for

**[16:10]** connecting to all the data sources and

**[16:13]** to ingest them into various memories

**[16:15]** that we have. uh so that uh the uh

**[16:19]** memory can be enriched not only from all

**[16:22]** the chat history or the user agent or

**[16:25]** agent user model interactions uh but

**[16:28]** also potentially from user user

**[16:30]** interactions. So for example, we have uh

**[16:34]** built connectors to slack uh to emails

**[16:38]** to meeting transcripts so that you can

**[16:42]** capture all those episodes into the

**[16:45]** memory system as well. The second agent

**[16:48]** is contact retrieval agent. And the

**[16:51]** contact retrieval agent is responsible

**[16:54]** for when you see a query that you can

**[16:56]** translate that query into subqueries

**[16:59]** into different pieces of memory or

**[17:02]** potentially into other uh context

**[17:05]** sources like rack systems where many

**[17:08]** enterprise have them today. And it is

**[17:10]** then responsible for assemble them

**[17:13]** together to form the overall uh context

**[17:17]** enrichment uh to queries. And so this

**[17:20]** can be done by just adding with it

**[17:22]** within the contract window or to be

**[17:25]** queried by models directly through a

**[17:27]** reasoning step through the MCP server

**[17:31]** and and we have a very early primitive

**[17:34]** forms of these two agents today and we

**[17:37]** are actively working to uh advance them

**[17:40]** and we believe these will be key models

**[17:42]** to enable an overall context engineering

**[17:46]** system. Um, so that's a uh uh overview

**[17:50]** of the Yes, please.

**[18:02]** >> Yes. So this this whole layer is

**[18:04]** software only and uh it can be deployed

**[18:09]** anywhere. It can be deployed uh in the

**[18:11]** cloud. AWS our co-host there can be

**[18:15]** deployed on the on the cloud. It can be

**[18:17]** deployed in your own data center. It can

**[18:20]** be deployed on your own laptop. It can

**[18:23]** potentially deploy in your phone as

**[18:25]** well. So so this is a software layer

**[18:27]** that can be deployed anywhere. And I

**[18:28]** didn't draw here. We do use some

**[18:30]** databases underneath as well that help

**[18:33]** us as sort of really the storage

**[18:36]** uh for these memory entities and for

**[18:39]** these profiles. And you can use this and

**[18:41]** then it should be

**[18:43]** >> Yeah. And the working memory uh runs on

**[18:47]** top of VRAM and persistent memory runs

**[18:50]** really on top of persistent storage. Uh

**[18:53]** and it can be any any of them. Yes.

**[18:56]** >> So this language agnostic. So for

**[18:58]** example the majority of my customers

**[19:01]** data are English. Would that work?

**[19:04]** >> Yeah. Yeah. It's a language agnostic. So

**[19:07]** it can be any of the languages.

**[19:13]** We first asked question thinking this

**[19:15]** programming language but programming

**[19:17]** language also you know the Python SDK

**[19:20]** will be only for Python but the other uh

**[19:22]** APIs because Python is the most popular

**[19:25]** but it can support the other languages

**[19:27]** other programming language as well. But

**[19:28]** in terms of data today it does support

**[19:31]** any kind of text data whatever is the

**[19:34]** language we do not support you know

**[19:37]** multimodel data yet uh but those will be

**[19:40]** coming also and those will be important

**[19:42]** such as voice or or or pictures or

**[19:46]** videos and then I think those will be

**[19:48]** important part of the memory also but we

**[19:50]** are only at the beginning of this

**[19:51]** journey here um and and I we are

**[19:55]** certainly not the only one doing it. I

**[19:57]** think there are many uh comrades or

**[20:00]** maybe there are better words for that

**[20:03]** people who share the same vision here

**[20:05]** and who are who are building it and uh

**[20:08]** and and these are uh some of the results

**[20:11]** we we gathered from the published

**[20:14]** materials

**[20:15]** uh of the benchmark uh using a benchmark

**[20:19]** for local and and that seems to be a

**[20:22]** popular benchmark with all the people

**[20:25]** who are working on memory.

**[20:26]** Um and uh uh actually I forgot to change

**[20:30]** the typo because we our latest

**[20:34]** 0.1

**[20:36]** is achieving the statewide uh in terms

**[20:38]** of local performance. Uh as you see some

**[20:41]** of the other players they will probably

**[20:44]** publish new data to elevate continue to

**[20:47]** elevate their performance as well. But

**[20:49]** from what we gathered from the published

**[20:52]** material, we saw that open AI uh is

**[20:56]** about 52%. So how this benchmark works

**[20:59]** is it feeds 10 long conversations

**[21:03]** u into the memory system and then it

**[21:06]** generate about 1900 questions. It would

**[21:09]** ask the model which is integrated with

**[21:11]** that particular memory system. If it

**[21:14]** doesn't have a memory, it it only will

**[21:16]** get very small percentage of those

**[21:18]** questions correctly. But with a memory

**[21:20]** system now, I can't answer all of them

**[21:22]** correctly. So the openi answer about 52%

**[21:25]** correctly and man with a memory system

**[21:28]** will event

**[21:37]** the numbers they have is what I got is

**[21:39]** 66 to 75%. they probably have new or

**[21:43]** better numbers uh as we make progress.

**[21:46]** Um I think uh uh when we launched the

**[21:50]** project in September we published

**[21:52]** numbers at 84.87%

**[21:55]** and in the last couple months uh with

**[21:57]** our new improvement uh our latest

**[22:00]** performance 93.25%.

**[22:03]** And from the numbers that we have seen I

**[22:05]** think this is a state of art uh in the

**[22:07]** episodic memory performance. uh we do

**[22:10]** see a new announcement from uh uh last

**[22:13]** weekend uh from uh Evermind and who I

**[22:17]** think will tank will be presenting

**[22:19]** today. They are publishing 92.3%

**[22:23]** which is a very good result uh as well.

**[22:25]** So I think now this is just one of the

**[22:28]** benchmarks. There are there are other

**[22:29]** benchmarks

**[22:30]** that are uh existing and I believe

**[22:34]** there's room for more benchmarks to be

**[22:36]** created to explore uh a deeper aspect of

**[22:41]** memory and uh and that's an area I think

**[22:44]** the industry can come together to

**[22:45]** advance so that we have a common

**[22:47]** framework. How do we make progress on

**[22:51]** the actual memory system that we build?

**[22:55]** Okay. Um, now I will end my presentation

**[22:59]** with a demo. Uh so this is a demo of of

**[23:04]** a map machine uh system at work in a

**[23:07]** typical enterprise environment which is

**[23:10]** our focus and our objective is to uh

**[23:15]** build this uh system for the enterprises

**[23:18]** that within their control whe either

**[23:21]** deployed in their own version private

**[23:23]** cloud AWS or any other cloud systems and

**[23:27]** uh or in into their own data center and

**[23:30]** uh there'll be users using it and in

**[23:32]** this demo it'll be Tom I'll be the

**[23:34]** enterprise user here and we have

**[23:37]** integrated with various data sources

**[23:39]** like emails and flags and the meeting

**[23:41]** transcripts and we also have integrated

**[23:44]** with two of the most common super agents

**[23:48]** uh one is maybe the most common super

**[23:50]** agent that's the uh the chatbot that

**[23:53]** open

**[23:55]** that we have integrated with that and we

**[23:57]** have also integrated with closed desktop

**[24:00]** That's uh actually the gaming uh perhaps

**[24:04]** is even more popular than CHP within the

**[24:08]** enterprise environment. It is part

**[24:11]** particularly good for coding as well as

**[24:14]** some other professional tasks such as

**[24:16]** creating powerpoints etc. So uh we we

**[24:20]** actually think it's a very common

**[24:22]** scenario for a typical uh worker like

**[24:26]** Charles uh to use more than one models

**[24:30]** and more than one agents for my daily

**[24:33]** work. Uh and in this case so here is a

**[24:36]** demo scenario I'm going to a typical

**[24:40]** knowledge worker in enterprise. I like

**[24:42]** to use checkp for general tasks which is

**[24:45]** quite common but I do like flow for

**[24:48]** specific professional task

**[24:51]** poweroint and other things. Uh now the

**[24:53]** task I got is I needed needed to prepare

**[24:55]** a presentation next week with a customer

**[24:59]** apex it's a it's a makeup name uh the uh

**[25:02]** with a with a particular customer and

**[25:05]** how I go about and doing it is I first

**[25:07]** work with KBD

**[25:09]** um and KPD is powered by mechain behind

**[25:13]** and uh so it will be able to uh retrieve

**[25:17]** the relevant information from my memory

**[25:20]** system about uh Apex tack from all the

**[25:24]** meeting minutes and emails and Slack

**[25:27]** conversation that we've had about this

**[25:30]** uh uh customer as well as from past AI

**[25:34]** uh chat box or chat history about them

**[25:37]** and it'll be able to summarize them

**[25:39]** deliver me information about the

**[25:41]** customer uh it will remember things

**[25:44]** about the product I'm going to present

**[25:46]** and it's also going to remember about me

**[25:48]** so it's gonna the profile memory going

**[25:50]** to deliver uh what is Charles like? uh

**[25:54]** what uh do I like you know what type of

**[25:58]** slides I like to make and what type of

**[26:00]** flow I like to follow and all those

**[26:02]** information will be automatically served

**[26:05]** as context into models and model will be

**[26:08]** able to generate in this case open AI

**[26:10]** model will be generating a presentation

**[26:12]** outline and but I don't like for the

**[26:16]** actual poweroint it's actually not

**[26:19]** yeah it's not good at that so then I

**[26:22]** will will you know bring up my clo uh

**[26:25]** desktop and uh now clo all those

**[26:28]** conversations with JBT is automatically

**[26:30]** real time captured by membership memory

**[26:32]** system and and clo will be able to use

**[26:35]** that interaction give me some additional

**[26:37]** advices and actually go ahead and

**[26:39]** generate a particle. So this shows a

**[26:41]** typical scenario where a knowledge

**[26:44]** worker like myself can use multiple

**[26:47]** agents, multiple models or connected

**[26:49]** through a memory fabric to getting a

**[26:51]** task done very easily.

**[26:53]** >> Yes.

**[26:54]** >> So when you use the chat GBT right based

**[26:58]** on the me machine do your interactions

**[27:01]** feed back to the memory?

**[27:03]** >> Yes.

**[27:04]** >> Yeah. when we are actually using the CHP

**[27:06]** those interactions are automatically in

**[27:09]** the background uh being remembered by

**[27:12]** yes and and and now let me show the

**[27:15]** video here

**[27:17]** all right so

**[27:20]** let's see I think it should be

**[27:24]** sorry the text is pretty small but I

**[27:25]** basically ask you to uh you're creating

**[27:28]** a presentation and if you recall what

**[27:30]** you can remember about the customer okay

**[27:33]** it it goes out Here they will remember

**[27:35]** about customers the key people the pain

**[27:37]** point they have etc etc and then it

**[27:40]** remembers about the product you know the

**[27:42]** product I'm presenting what they recall

**[27:44]** from the memory and then it records

**[27:47]** about me you know my styles and so on

**[27:50]** but it does ask me a few more questions

**[27:51]** uh in order for it to creating this

**[27:53]** presentation and uh and so now I'll give

**[27:57]** the answers to these questions uh the

**[28:00]** meeting purpose design tone and comedy

**[28:02]** slides etc.

**[28:04]** Okay. Now the open AI models with all

**[28:07]** these information uh can generate a

**[28:10]** slide uh outline here the slide one kind

**[28:14]** of the context challenge inside the

**[28:15]** solution etc. It create a slide

**[28:19]** presentation. Uh and uh yeah, business

**[28:22]** impact why now next steps. Okay, that's

**[28:24]** great. Uh I like it. Uh but I don't

**[28:28]** really like JPT to do my actual slide

**[28:31]** work. So I go to clone uh desktop and

**[28:35]** this is a question the clone. So I say

**[28:37]** do you remember what I just created? It

**[28:40]** says okay I I do see it and uh let me

**[28:43]** retrieve it from memory. The clone is

**[28:44]** also powered by me. the same memory

**[28:47]** machine instance that's connected to

**[28:48]** KPBD and it remembers those eight slides

**[28:52]** in slightly different formats but

**[28:54]** capture the key information about those

**[28:56]** uh eight eight slides. uh here are the

**[29:00]** you know other information remember from

**[29:02]** the memory the key context there and

**[29:05]** then uh then I asked you know I asked

**[29:08]** for second opinion here now and I think

**[29:10]** many of us too sometimes we ask multiple

**[29:12]** models to second opinion so I said okay

**[29:16]** would you have any suggestion any

**[29:17]** improvement you can make to this outline

**[29:20]** says okay I have five five suggestions

**[29:23]** uh something is missing something is too

**[29:26]** abstract good and uh and here are some

**[29:30]** suggestion I have. Now it's up to me to

**[29:32]** decide what are those suggestion I take,

**[29:34]** which one I don't take. And in this

**[29:36]** example, I say great um but just go with

**[29:40]** number one like the first first

**[29:41]** suggestion and uh ignore the rest and go

**[29:44]** ahead and create the PowerPoint. Uh as

**[29:47]** of now 12 goes to work um and uh it will

**[29:51]** take a second. In fact, it took about uh

**[29:55]** you know 10 minutes or so for it to work

**[29:57]** work through it. Then we fast forward a

**[29:59]** little bit uh and to to actually uh

**[30:02]** create the the slides here. So so you'll

**[30:05]** see it's creating

**[30:07]** actually nine nine slides here uh as we

**[30:10]** have taken one suggestion from it and

**[30:13]** voila you have the uh the slides is

**[30:16]** created. uh and this is a seamless

**[30:19]** process where you use multiple agents

**[30:21]** powered by different models but

**[30:22]** connected to a common converg management

**[30:25]** system that can deliver uh the output

**[30:28]** you need and uh and this is a simple

**[30:30]** example uh pretty common scenario I

**[30:33]** think all of us do that there are many

**[30:35]** other common scenarios where a common

**[30:38]** converge AI memory fabric can enable

**[30:42]** this multi- aent collaboration to happen

**[30:45]** seamlessly

**[30:46]** Okay. All right. So that's the uh uh

**[30:49]** example I have and then as you see there

**[30:52]** there's many use cases for something

**[30:54]** like this. Now whether you're creating

**[30:57]** assistance to various roles, whether

**[31:00]** it's executives, creative content

**[31:02]** creators, or whether you're serving

**[31:04]** external clients uh or financial advice

**[31:07]** or customer support, a memory system is

**[31:12]** quintessential uh in delivering uh the

**[31:16]** state-of-the-art agents uh for these

**[31:18]** purposes. Uh so try it out. Uh here is a

**[31:23]** barcode for the project and this will

**[31:26]** connect you to GitHub to our playground

**[31:30]** to uh uh other resources, documentations

**[31:33]** and so on about the project that will

**[31:35]** dive into much more details and my

**[31:37]** presentation and we also have a team

**[31:40]** here uh that you can scan this to

**[31:43]** schedule a meeting that can happen

**[31:44]** today. We have a room oneonone with our

**[31:47]** team to learn more about the memory. And

**[31:50]** for those folks on the zoom, you know,

**[31:52]** you can also use this to to schedule

**[31:55]** meetings uh with us uh to dive into more

**[31:58]** details. So, thank you very much.


---

*이 문서는 YouTube 자막을 기반으로 자동 생성되었습니다.*
*생성 도구: YouTube-to-MD Skill*
